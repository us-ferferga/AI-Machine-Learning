{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ca55ead",
   "metadata": {},
   "source": [
    "# Aprendizaje automático relacional\n",
    "\n",
    "#### Fernando Jesús Fernández Gallardo\n",
    "#### Carmen Galván López"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a979dd0c",
   "metadata": {},
   "source": [
    "# Librerías externas y variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede9ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from pandas import read_csv\n",
    "from numpy import mean\n",
    "from sklearn import preprocessing, model_selection, naive_bayes, neighbors\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy import stats\n",
    "from copy import copy\n",
    "# Suprimir los warnings relacionados con la siguiente versión de SciPy\n",
    "from warnings import filterwarnings\n",
    "\n",
    "semilla = 86\n",
    "test_size= .33\n",
    "filterwarnings(\"ignore\", category=FutureWarning)\n",
    "filterwarnings(\"ignore\", category=UserWarning)\n",
    "cross_val = None\n",
    "codificador_objetivo = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b90d68",
   "metadata": {},
   "source": [
    "# Definición de los modelos\n",
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6bc29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ejecuta el modelo Naive Bayes sobre el dataset, tanto para datos no relacionales como\n",
    "relacionales\n",
    "\n",
    "@param tuple(atributos_entrenamiento, atributos_prueba, atributos_codificados) - Variables de los atributos a utilizar\n",
    "@param tuple(objetivo_entrenamiento, objetivo_prueba, objetivo_codificado) - Variables del objetivo a utilizar\n",
    "@param suavizado = 1 - Suavizado de Laplace a aplicar\n",
    "\"\"\"\n",
    "def nb(atrs, obj, suavizado = 1):\n",
    "    global codificador_objetivo, cv\n",
    "    (at_ent, at_pr, at_cod) = atrs\n",
    "    (ob_ent, ob_pr, ob_cod) = obj\n",
    "    clasif_NB = naive_bayes.MultinomialNB(alpha=suavizado)\n",
    "    clasif_NB.fit(at_ent, ob_ent)\n",
    "\n",
    "    #Calculamos la cantidad de ejemplos para cada clase y los logaritmos\n",
    "    for clase, cantidad_ejemplos_clase, log_probabilidad_clase in zip(\n",
    "            clasif_NB.classes_, clasif_NB.class_count_, clasif_NB.class_log_prior_):\n",
    "        print(f\"Cantidad de ejemplos para la clase {clase}: {cantidad_ejemplos_clase}\")\n",
    "        print(f\"Logaritmo de la probabilidad aprendida para la clase {clase}: {log_probabilidad_clase}\")\n",
    "    \n",
    "    print(\"\\nRESULTADOS DEL ENTRENAMIENTO\")\n",
    "    #Probamos la predicción con los atributos de prueba\n",
    "    print(f'Predicción con Naive Bayes: {codificador_objetivo.inverse_transform(clasif_NB.predict(at_pr))}')\n",
    "    #Hacemos el score con naive bayes\n",
    "    print(f'Precisión con Naive Bayes: {clasif_NB.score(at_pr, ob_pr)}')\n",
    "    #Hacemos el score con cross validation\n",
    "    print(f'Precisión con cross validation: {cross_val_score(clasif_NB, at_cod, ob_cod, cv=cv)}')\n",
    "    #Hacemos la media de score de cross validation, ya que al final es lo que nos interesa\n",
    "    print(f'Media de precisión: {mean(cross_val_score(clasif_NB, at_cod, ob_cod, cv=cv))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cd764c",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6313e42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@param tuple(atributos_entrenamiento, atributos_prueba, atributos_codificados) - Variables de los atributos a utilizar\n",
    "@param tuple(objetivo_entrenamiento, objetivo_prueba, objetivo_codificado) - Variables del objetivo a utilizar\n",
    "\"\"\"\n",
    "def knn(atrs, obj, ejemplos):\n",
    "    global codificador_objetivo, cv\n",
    "    (at_ent, at_pr, at_cod) = atrs\n",
    "    (ob_ent, ob_pr, ob_cod) = obj\n",
    "\n",
    "    def encontrar_mejor_k(at_cod, ob_cod, k_range):\n",
    "        puntajes_por_k = []\n",
    "\n",
    "        for k in k_range:\n",
    "            # Crear clasificador KNN con el valor actual de k\n",
    "            knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "            # Realizar validación cruzada y obtener los puntajes\n",
    "            puntajes = cross_val_score(knn, at_cod, ob_cod, scoring='accuracy', cv=cv)\n",
    "\n",
    "            # Calcular el puntaje medio de validación cruzada\n",
    "            puntaje_medio = puntajes.mean()\n",
    "\n",
    "            # Almacenar el puntaje correspondiente al valor de k\n",
    "            puntajes_por_k.append((k, puntaje_medio))\n",
    "\n",
    "        return puntajes_por_k\n",
    "\n",
    "    encontrar_mejor_k(at_cod, ob_cod, k_range=list(range(1, 20)))\n",
    "    \n",
    "    #Según el k_scores, podemos ver que a partir de 10 vecinos es totalmente irrelevante cuantos pongamos, \n",
    "    #así que utilizaremos n_neighbors=10,\n",
    "    #Definimos y entrenamos kNN\n",
    "\n",
    "    clasif_kNN = neighbors.KNeighborsClassifier(n_neighbors=10, metric='hamming')\n",
    "\n",
    "    clasif_kNN.fit(at_ent, ob_ent)\n",
    "\n",
    "    # Probamos la predicción con los atributos de prueba\n",
    "    print('Predicción kNN:', codificador_objetivo.inverse_transform(clasif_kNN.predict(at_pr)))\n",
    "\n",
    "    # Hacemos el score con kNN\n",
    "    print('Precisión kNN:', clasif_kNN.score(at_pr, ob_pr))\n",
    "\n",
    "    # Hacemos el score con cross validation utilizando los datos de entrenamiento\n",
    "    cv_scores = cross_val_score(clasif_kNN, at_ent, ob_ent, cv=cv)\n",
    "    print('Precisión cross validation:', mean(cv_scores))\n",
    "    \n",
    "    \"\"\"\n",
    "    Vamos a dar algunos datos sobre knn como pueden ser la distancia, los vecinos más cercanos a un dato,\n",
    "    y las clases de esos vecinos\n",
    "    \"\"\"\n",
    "    distancias, vecinos = clasif_kNN.kneighbors(ejemplos)\n",
    "    print(\"Primer ejemplo nuevo:\", ejemplos[0])\n",
    "    print(\"10 vecinos más cercanos:\")\n",
    "    print([vecinos[0]])\n",
    "    print(\"Distancias a esos vecinos (cantidad de atributos con valores distintos / cantidad total de atributos):\")\n",
    "    print(distancias[0])\n",
    "\n",
    "    print(\"Clases a las que pertenecen esos vecinos: \", [objetivo[index] for index in vecinos[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5d913e",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4dbd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@param tuple(atributos_entrenamiento, atributos_prueba, atributos_codificados) - Variables de los atributos a utilizar\n",
    "@param tuple(objetivo_entrenamiento, objetivo_prueba, objetivo_codificado) - Variables del objetivo a utilizar\n",
    "\"\"\"\n",
    "def svc(atrs, obj):\n",
    "    global cv\n",
    "    (at_ent, at_pr, at_cod) = atrs\n",
    "    (ob_ent, ob_pr, ob_cod) = obj\n",
    "    classif_SVC = SVC().fit(at_ent, ob_ent)\n",
    "\n",
    "    #Probamos la predicción con los atributos de prueba\n",
    "    print(f'Predicción SVC: {codificador_objetivo.inverse_transform(classif_SVC.predict(at_pr))}')\n",
    "    #Hacemos el score con kNN\n",
    "    print(f'Precisión SVC: {classif_SVC.score(at_pr, ob_pr)}')\n",
    "    #Hacemos el score con cross validation\n",
    "    print(f'Precisión cross validation: {mean(cross_val_score(classif_SVC, at_cod, ob_cod, cv=cv))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62d4c7b",
   "metadata": {},
   "source": [
    "# Procesamiento inicial de los datos en bruto\n",
    "#### Lectura y eliminación del identificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aea927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leemos los archivos\n",
    "vertices = read_csv('data/political-books-nodes.csv')\n",
    "aristas = read_csv('data/political-books-edges.csv')\n",
    "\n",
    "del(vertices['Id'])\n",
    "\n",
    "#Mostramos las primeras 35 filas\n",
    "vertices.head(35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f366b383",
   "metadata": {},
   "source": [
    "#### Validación y selección de los datos brutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Comprobamos que el dataset es válido verificando que no existen duplicados\n",
    "\"\"\"\n",
    "if len(vertices) != len(set(vertices['Label'])):\n",
    "    raise ValueError(\"El dataset no es válido ya que contiene duplicados\")\n",
    "\"\"\"\n",
    "La mejor forma de identificar cada uno de los elementos que forma parte\n",
    "del conjunto de entrenamiento es el nombre del propio libro (que en el dataset\n",
    "se llama 'Label') en vez del ID o cualquier otro tipo de indentificador más\n",
    "complejo. De esta forma, también es más fácil identificar elementos duplicados\n",
    "(si los hubiera)\n",
    "\"\"\"\n",
    "atributos = vertices['Label']\n",
    "\"\"\"\n",
    "Nuestro objetivo es predecir la ideología política del autor basándonos en\n",
    "sus obras, por lo que el objetivo que perseguimos en nuestro modelo\n",
    "es el de la ideología política\n",
    "\"\"\"\n",
    "objetivo = vertices['political_ideology']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5904808a",
   "metadata": {},
   "source": [
    "#### Codificación de los datos e inicialización de la CrossValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1361f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Para poder trabajar con los datos que tenemos, necesitamos convertirlos en un formato que sklearn pueda \"entender\".\n",
    "Debemos de hacer que nuestros datos \"planos\" sean para sklearn objetos \"comparables\", dependiendo del tipo de\n",
    "ordenación que nosotros veamos más apropiada para el método en cuestión\n",
    "(de una manera similar hacemos en Java cuando implementamos la interfaz 'Comparable' y el método compareTo)\n",
    "\n",
    "El codificador adecuado para la variable objetivo es LabelEncoder, que trabaja\n",
    "con una lista o array unidimensional de sus valores y admite cadenas\n",
    "\n",
    "\"\"\"\n",
    "# Codificadores\n",
    "codificador_atributos = preprocessing.LabelEncoder()\n",
    "codificador_objetivo = preprocessing.LabelEncoder()\n",
    "# Datos codificados\n",
    "atributos_codificados = codificador_atributos.fit_transform(atributos)\n",
    "objetivo_codificado = codificador_objetivo.fit_transform(objetivo)\n",
    "\n",
    "\"\"\"\n",
    "ShuffleSplit es necesario para la CrossValidation\n",
    "\"\"\"\n",
    "cv = ShuffleSplit(n_splits=10, test_size=test_size, random_state=semilla)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177b9190",
   "metadata": {},
   "source": [
    "# Métricas no relacionales\n",
    "#### División en conjunto de entrenamiento y conjunto de prueba\n",
    "\n",
    "Partimos el atributo y el objetivo en dos conjuntos: entrenamiento y prueba.<br />\n",
    "El de entrenamiento lo utilizaremos para la ejecución de los algoritmos, mientras que el de prueba sirve para evaluar su rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f3f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "(atributos_entrenamiento,\n",
    " atributos_prueba,\n",
    " objetivo_entrenamiento,\n",
    " objetivo_prueba) = model_selection.train_test_split(\n",
    "        atributos_codificados,\n",
    "        objetivo_codificado,\n",
    "        # Valor de la semilla aleatoria para que el muestreo sea reproducible a pesar de ser aleatorio\n",
    "        random_state=semilla,\n",
    "        test_size=test_size,\n",
    "        stratify=objetivo_codificado\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568cc4f9",
   "metadata": {},
   "source": [
    "El método reshape solo cambia la forma del array, pero no su contenido.\n",
    "Los clasificadores de sklearn espera un array 2D porque puede manejar\n",
    "múltiples características por muestra, pero en nuestro caso solo tenemos una característica por muestra,\n",
    "que es el nombre del libro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5a78f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "atr_cod_reshaped = atributos_codificados.reshape(-1, 1)\n",
    "atr_pr_reshaped = atributos_prueba.reshape(-1, 1)\n",
    "atr_ent_reshaped = atributos_entrenamiento.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a283d7",
   "metadata": {},
   "source": [
    "Ejecutamos los modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d079fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"======= NAIVE BAYES (no relacional) =======\\n\")\n",
    "nb((atr_ent_reshaped, atr_pr_reshaped, atr_cod_reshaped),\n",
    "           (objetivo_entrenamiento, objetivo_prueba, objetivo_codificado))\n",
    "\n",
    "print(\"\\n\\n======= kNN (no relacional) =======\\n\")\n",
    "# Otorgamos a kNN nuevos ejemplos arbitrarios sobre los que aplicar el algoritmo entrenado para ver su clasificación\n",
    "ejemplos_knn = [[1.], [20.], [2.]]\n",
    "knn((atr_ent_reshaped, atr_pr_reshaped, atr_cod_reshaped),\n",
    "           (objetivo_entrenamiento, objetivo_prueba, objetivo_codificado), ejemplos_knn)\n",
    "\n",
    "print(\"\\n\\n======= SVC (no relacional) =======\\n\")\n",
    "svc((atr_ent_reshaped, atr_pr_reshaped, atr_cod_reshaped),\n",
    "           (objetivo_entrenamiento, objetivo_prueba, objetivo_codificado))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df5be2a",
   "metadata": {},
   "source": [
    "# Métricas relacionales\n",
    "Definimos las funciones que vamos a utilizar para obtener las diferentes métricas relacionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5763c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Métrica relacionada con la centralidad de un grafo. Devuelve el número de conexiones (enlaces) que tiene ese nodo.\n",
    "Los nodos con mayor grado se consideran más centrales en términos de conectividad.\n",
    "\"\"\"\n",
    "def getDegreeCentrality(grafo):\n",
    "    centrality = nx.degree_centrality(grafo)\n",
    "    return list(centrality.values())\n",
    "\"\"\"\n",
    "Métrica relacionada con la centralidad. Si un nodo tiene un mayor grado,\n",
    "significa que está conectado a un mayor número de otros nodos en el grafo.\n",
    "\"\"\"\n",
    "def getHighClosenessCentrality(grafo):\n",
    "    high_closeness = nx.closeness_centrality(grafo, u=None, distance=None, wf_improved=True)\n",
    "    return list(high_closeness.values())\n",
    "\"\"\"\n",
    "Métrica relacionada con la centralidad.\n",
    "Un nodo con un alto valor de \"high betweenness centrality\" actúa como un puente o un punto de conexión\n",
    "crucial entre diferentes partes del grafo.\n",
    "\"\"\"\n",
    "def getHighBetweennessCentrality(grafo):\n",
    "    betweenness = nx.betweenness_centrality(grafo, normalized=True, endpoints=False)\n",
    "    return list(betweenness.values())\n",
    "\"\"\"\n",
    "Es una medida que cuantifica qué tan conectados están los vecinos\n",
    "de un nodo en comparación con todas las posibles conexiones entre ellos.\n",
    "\"\"\"\n",
    "def getCoeficienteClustering(grafo):\n",
    "    # Obtener el coeficiente de clustering para cada vértice\n",
    "    coeficientes = nx.clustering(grafo)\n",
    "    return list(coeficientes.values())\n",
    "\"\"\"\n",
    "EXTRA: Modularidad. Esta métrica no nos es útil para ninguno de los algoritmos de ML que vamos\n",
    "a utilizar, pero lo definimos para tener aún más información sobre el dataset que estamos estudiando.\n",
    "\n",
    "Métrica relacionada con la detección de comunidades. Si un nodo tiene un mayor grado,\n",
    "significa que está conectado a un mayor número de otros nodos en el grafo.\n",
    "\"\"\"\n",
    "def getModularidad(grafo):\n",
    "    particion = nx.community.greedy_modularity_communities(grafo)\n",
    "    modularidad = nx.community.modularity(grafo, particion)\n",
    "    return modularidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0abca4",
   "metadata": {},
   "source": [
    "### Cálculo de las métricas relacionales\n",
    "Generamos el grafo y añadimos las métricas al conjunto de vértices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c949ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "grafo = nx.from_pandas_edgelist(aristas, 'Source', 'Target')\n",
    "vertices_r = copy(vertices)\n",
    "\n",
    "vertices_r = vertices_r.assign(Degree_Centrality = getDegreeCentrality(grafo))\n",
    "vertices_r = vertices_r.assign(High_closeness_centrality = getHighClosenessCentrality(grafo))\n",
    "vertices_r = vertices_r.assign(High_betweenness_centrality = getHighBetweennessCentrality(grafo))\n",
    "vertices_r = vertices_r.assign(Clustering = getCoeficienteClustering(grafo))\n",
    "\n",
    "print(f\"La modularidad del grafo es: {getModularidad(grafo)}\")\n",
    "\n",
    "G = nx.read_graphml('data/political-books-network.graphml')\n",
    "nx.draw_random(G, with_labels=True)\n",
    "vertices_r.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9bd683",
   "metadata": {},
   "source": [
    "## Selección de datos relacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdccc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#División de atributos y target\n",
    "atributos_r = vertices_r[['Label', 'Degree_Centrality', 'High_closeness_centrality',\n",
    "                     'High_betweenness_centrality','Clustering']]\n",
    "\n",
    "atributos_r.loc[:, 'Label'] = atributos_codificados\n",
    "\n",
    "#División de los datos en entreamiento y objetivo\n",
    "(atributos_entrenamiento_r,\n",
    " atributos_prueba_r,\n",
    " objetivo_entrenamiento_r,\n",
    " objetivo_prueba_r) = model_selection.train_test_split(\n",
    "        atributos_r,\n",
    "        objetivo_codificado,\n",
    "        # Valor de la semilla aleatoria para que el muestreo sea reproducible a pesar de ser aleatorio\n",
    "        random_state=semilla,\n",
    "        test_size=test_size,\n",
    "        stratify=objetivo_codificado\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5885b22b",
   "metadata": {},
   "source": [
    "Ejecutamos los modelos nuevamente, esta vez con los datos relaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f31d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"======= NAIVE BAYES (relacional) =======\\n\")\n",
    "nb((atributos_entrenamiento_r, atributos_prueba_r, atributos_r),\n",
    "           (objetivo_entrenamiento_r, objetivo_prueba_r, objetivo_codificado))\n",
    "\n",
    "print(\"\\n\\n======= kNN (relacional) =======\\n\")\n",
    "ejemplos_knn_r = [[1., 0.23, 0.4321, 0.001, 0.333333], [20., 0.115, 0.3095, 0.00521, 0.5], [2., 0.0579, 0.3151, 0.0099, 0.6]]\n",
    "knn((atributos_entrenamiento_r, atributos_prueba_r, atributos_r),\n",
    "           (objetivo_entrenamiento_r, objetivo_prueba_r, objetivo_codificado), ejemplos_knn_r)\n",
    "\n",
    "print(\"\\n\\n======= SVC (relacional) =======\\n\")\n",
    "svc((atributos_entrenamiento_r, atributos_prueba_r, atributos_r),\n",
    "           (objetivo_entrenamiento_r, objetivo_prueba_r, objetivo_codificado))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f09167c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
