{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ca55ead",
   "metadata": {},
   "source": [
    "# Aprendizaje automático relacional\n",
    "\n",
    "#### Fernando Jesús Fernández Gallardo\n",
    "#### Carmen Galván López"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a979dd0c",
   "metadata": {},
   "source": [
    "## Preparación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda48683",
   "metadata": {},
   "source": [
    "#### Imports y variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede9ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn import preprocessing, model_selection, naive_bayes, neighbors\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from scipy import stats\n",
    "\n",
    "semilla = 86\n",
    "test_size= .33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62d4c7b",
   "metadata": {},
   "source": [
    "#### Lectura y procesamiento inicial de los datos brutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aea927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leemos los archivos\n",
    "vertices = read_csv('data/political-books-nodes.csv')\n",
    "aristas = read_csv('data/political-books-edges.csv')\n",
    "\n",
    "#Borramos la columna ID\n",
    "del(vertices['Id'])\n",
    "\n",
    "#Mostramos las primeras 35 filas\n",
    "vertices.head(35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f366b383",
   "metadata": {},
   "source": [
    "#### Selección y validación de los datos brutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Comprobamos que el dataset es válido verificando que no existen duplicados\n",
    "\"\"\"\n",
    "if len(vertices) != len(set(vertices['Label'])):\n",
    "    raise ValueError(\"El dataset no es válido ya que contiene duplicados\")\n",
    "\"\"\"\n",
    "La mejor forma de identificar cada uno de los elementos que forma parte\n",
    "del conjunto de entrenamiento es el nombre del propio libro (que en el dataset\n",
    "se llama 'Label') en vez del ID o cualquier otro tipo de indentificador más\n",
    "complejo. De esta forma, también es más fácil identificar elementos duplicados\n",
    "(si los hubiera)\n",
    "\"\"\"\n",
    "atributos = vertices['Label']\n",
    "\"\"\"\n",
    "Nuestro objetivo es predecir la ideología política del autor basándonos en\n",
    "sus obras, por lo que el objetivo que perseguimos en nuestro modelo\n",
    "es el de la ideología política\n",
    "\"\"\"\n",
    "objetivo = vertices['political_ideology']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5904808a",
   "metadata": {},
   "source": [
    "## Inicio del entrenamiento\n",
    "#### Codificación del objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1361f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Para poder trabajar con los datos que tenemos, necesitamos convertirlos en un formato que sklearn pueda \"entender\".\n",
    "Debemos de hacer que nuestros datos \"planos\" sean para sklearn objetos \"comparables\", dependiendo del tipo de\n",
    "ordenación que nosotros veamos más apropiada para el método en cuestión\n",
    "(de una manera similar hacemos en Java cuando implementamos la interfaz 'Comparable' y el método compareTo)\n",
    "\n",
    "El codificador adecuado para la variable objetivo es LabelEncoder, que trabaja\n",
    "con una lista o array unidimensional de sus valores y admite cadenas\n",
    "\n",
    "\"\"\"\n",
    "# Codificadores\n",
    "codificador_atributos = preprocessing.LabelEncoder()\n",
    "codificador_objetivo = preprocessing.LabelEncoder()\n",
    "# Datos codificados\n",
    "atributos_codificados = codificador_atributos.fit_transform(atributos)\n",
    "objetivo_codificado = codificador_objetivo.fit_transform(objetivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177b9190",
   "metadata": {},
   "source": [
    "#### División en conjunto de entrenamiento y conjunto de prueba\n",
    "\n",
    "Partimos el atributo y el objetivo en dos, de entrenamiento y de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f3f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "(atributos_entrenamiento,\n",
    " atributos_prueba,\n",
    " objetivo_entrenamiento,\n",
    " objetivo_prueba) = model_selection.train_test_split(\n",
    "        atributos_codificados,\n",
    "        objetivo_codificado,\n",
    "        # Valor de la semilla aleatoria para que el muestreo sea reproducible a pesar de ser aleatorio\n",
    "        random_state=semilla,\n",
    "        test_size=test_size,\n",
    "        stratify=objetivo_codificado\n",
    ")\n",
    "\n",
    "#Creamos nuevos ejemplos para futuras operaciones\n",
    "nuevos_ejemplos = [[1.], [20.], [2.]]\n",
    "\n",
    "\"\"\"\n",
    "ShuffleSplit es necesario para la CrossValidation\n",
    "\"\"\"\n",
    "cv = ShuffleSplit(n_splits=10, test_size=test_size, random_state=semilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5a78f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "El método reshape solo cambia la forma del array, pero no su contenido.\n",
    "Los clasificadores de sklearn espera un array 2D porque puede manejar\n",
    "múltiples características por muestra, pero en nuestro caso solo tenemos una característica por muestra,\n",
    "que es el nombre del libro.\n",
    "\"\"\"\n",
    "atr_cod_reshaped = atributos_codificados.reshape(-1, 1)\n",
    "atr_pr_reshaped = atributos_prueba.reshape(-1, 1)\n",
    "atr_ent_reshaped = atributos_entrenamiento.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b90d68",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "#### No relacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6bc29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "suavizado = 1\n",
    "\n",
    "clasif_NB = naive_bayes.MultinomialNB(alpha=suavizado)\n",
    "clasif_NB.fit(atr_ent_reshaped, objetivo_entrenamiento)\n",
    "\n",
    "#Calculamos la cantidad de ejemplos para cada clase y los logaritmos\n",
    "for clase, cantidad_ejemplos_clase, log_probabilidad_clase in zip(\n",
    "        clasif_NB.classes_, clasif_NB.class_count_, clasif_NB.class_log_prior_):\n",
    "    print(f\"Cantidad de ejemplos para la clase {0}: {1}\", clase, cantidad_ejemplos_clase)\n",
    "    print(f\"Logaritmo de la probabilidad aprendida para la clase {0}: {1}\", clase, log_probabilidad_clase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f2c42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probamos la predicción con los atributos de prueba\n",
    "print('Predicción con Naive Bayes: ', codificador_objetivo.inverse_transform(clasif_NB.predict(atr_pr_reshaped)))\n",
    "#Hacemos el score con naive bayes\n",
    "print('Precisión con Naive Bayes: ', clasif_NB.score(atr_pr_reshaped, objetivo_prueba))\n",
    "#Hacemos el score con cross validation\n",
    "print('Precisión con cross validation: ', cross_val_score(clasif_NB, atr_cod_reshaped, objetivo_codificado, cv=cv))\n",
    "#Hacemos la media de score de cross validation, ya que al final es lo que nos interesa\n",
    "print(f'Media de precisión: {0}', np.mean(cross_val_score(clasif_NB, atr_cod_reshaped, objetivo_codificado, cv=cv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cd764c",
   "metadata": {},
   "source": [
    "## KNN no relacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6313e42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_mejor_k(atributos, objetivo, k_range, cv=5):\n",
    "    puntajes_por_k = []\n",
    "\n",
    "    # Convertir los atributos en un array bidimensional con una sola columna\n",
    "    atributos = np.array(atributos).reshape(-1, 1)\n",
    "\n",
    "    for k in k_range:\n",
    "        # Crear clasificador KNN con el valor actual de k\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "        # Suprimir los warnings relacionados con la siguiente versión de SciPy\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "\n",
    "            # Realizar validación cruzada y obtener los puntajes\n",
    "            puntajes = cross_val_score(knn, atributos, objetivo, cv=cv, scoring='accuracy')\n",
    "\n",
    "        # Calcular el puntaje medio de validación cruzada\n",
    "        puntaje_medio = puntajes.mean()\n",
    "\n",
    "        # Almacenar el puntaje correspondiente al valor de k\n",
    "        puntajes_por_k.append((k, puntaje_medio))\n",
    "\n",
    "    return puntajes_por_k\n",
    "\n",
    "encontrar_mejor_k(atributos_codificados, objetivo_codificado, k_range=list(range(1, 20)), cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245753e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Según el k_scores, podemos ver que a partir de 10 vecinos es totalmente irrelevante cuantos pongamos, \n",
    "#así que utilizaremos n_neighbors=10,\n",
    "#Definimos y entrenamos kNN\n",
    "\n",
    "clasif_kNN = neighbors.KNeighborsClassifier(n_neighbors=10, metric='hamming')\n",
    "\n",
    "clasif_kNN.fit(atr_ent_reshaped, objetivo_entrenamiento)\n",
    "\n",
    "# Probamos la predicción con los atributos de prueba\n",
    "print('Predicción kNN:', codificador_objetivo.inverse_transform(clasif_kNN.predict(atr_pr_reshaped)))\n",
    "\n",
    "# Hacemos el score con kNN\n",
    "print('Precisión kNN:', clasif_kNN.score(atr_pr_reshaped, objetivo_prueba))\n",
    "\n",
    "# Hacemos el score con cross validation utilizando los datos de entrenamiento\n",
    "cv_scores = cross_val_score(clasif_kNN, atr_ent_reshaped, objetivo_entrenamiento, cv=cv)\n",
    "print('Precisión cross validation:', np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64a1a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a dar algunos datos sobre knn como pueden ser la distancia, los vecinos más cercanos a un dato, \n",
    "#y las clases de esos vecinos\n",
    "\n",
    "distancias, vecinos = clasif_kNN.kneighbors(nuevos_ejemplos)\n",
    "print(\"Primer ejemplo nuevo:\", nuevos_ejemplos[0])\n",
    "print(\"10 vecinos más cercanos:\")\n",
    "print([vecinos[0]])\n",
    "print(\"Distancias a esos vecinos (cantidad de atributos con valores distintos / cantidad total de atributos):\")\n",
    "print(distancias[0])  \n",
    "def obtenerClases(vecinos):\n",
    "    l=[]\n",
    "    for index in vecinos[0]:\n",
    "        l.append(objetivo[index])\n",
    "    return l\n",
    "print(\"Clases a las que pertenecen esos vecinos: \", obtenerClases(vecinos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5d913e",
   "metadata": {},
   "source": [
    "## SVC no relacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4dbd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a utilizar este modelo ya que nos viene bien al tener un dataset pequeño. Este modelo aumenta\n",
    "#el tiempo de entrenamiento cuadrátricamente con el número de ejemplos\n",
    "\n",
    "classif_SVC = SVC().fit(atr_ent_reshaped, objetivo_entrenamiento)\n",
    "\n",
    "\n",
    "#Probamos la predicción con los atributos de prueba\n",
    "print('Predicción SVC: ', classif_SVC.predict(atr_pr_reshaped))\n",
    "#Hacemos el score con kNN\n",
    "print('Precisión SVC: ', classif_SVC.score(atr_pr_reshaped, objetivo_prueba))\n",
    "#Hacemos el score con cross validation\n",
    "print(f'Precisión cross validation: {0}', np.mean(cross_val_score(classif_SVC, atr_cod_reshaped, objetivo_codificado, cv=cv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df5be2a",
   "metadata": {},
   "source": [
    "## Sacar métricas relacionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c949ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el grafo desde el archivo\n",
    "grafo = nx.from_pandas_edgelist(aristas, 'Source', 'Target')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014076d",
   "metadata": {},
   "source": [
    "#### Degree centrality.\n",
    "\n",
    "Métrica relacionada con la centralidad. El número de conexiones (enlaces) que tiene ese nodo. Los nodos con mayor grado se consideran más centrales en términos de conectividad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdabc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenerDegreeCentrality(grafo):\n",
    "    centrality = nx.degree_centrality(grafo)\n",
    "    return list(centrality.values())\n",
    "\n",
    "# Obtener la lista de Degree Centrality\n",
    "degree_centrality = obtenerDegreeCentrality(grafo)\n",
    "\n",
    "# Añadirlo a la tabla\n",
    "vertices['Degree_Centrality'] = degree_centrality\n",
    "vertices.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b9d04b",
   "metadata": {},
   "source": [
    "#### High closeness centrality.\n",
    "\n",
    "Métrica relacionada con la centralidad. Si un nodo tiene un mayor grado, significa que está conectado a un mayor número de otros nodos en el grafo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeab02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcularHighClosenessCentrality(grafo):\n",
    "    high_closeness = nx.closeness_centrality(grafo, u=None, distance=None, wf_improved=True)\n",
    "    return list(high_closeness.values())\n",
    "\n",
    "# Calcular el high closeness centrality\n",
    "high_closeness = calcularHighClosenessCentrality(grafo)\n",
    "\n",
    "# Añadirlo a la tabla\n",
    "vertices['High_closeness_centrality'] = high_closeness\n",
    "vertices.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6798eb69",
   "metadata": {},
   "source": [
    "#### High betweenness centrality.\n",
    "\n",
    "Métrica relacionada con la centralidad. Un nodo con un alto valor de \"high betweenness centrality\" actúa como un puente o un punto de conexión crucial entre diferentes partes del grafo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a59bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcularHighBetweennessCentrality(grafo):\n",
    "    betweenness = nx.betweenness_centrality(grafo, normalized=True, endpoints=False)\n",
    "    return list(betweenness.values())\n",
    "\n",
    "# Calcular el high betweenness centrality\n",
    "high_betweenness = calcularHighBetweennessCentrality(grafo)\n",
    "\n",
    "# Añadirlo a la tabla\n",
    "vertices['High_betweenness_centrality'] = high_betweenness\n",
    "vertices.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdb4d5a",
   "metadata": {},
   "source": [
    "#### Coeficiente de clustering.\n",
    "\n",
    "Es una medida que cuantifica qué tan conectados están los vecinos de un nodo en comparación con todas las posibles conexiones entre ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa90d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenerCoeficienteClustering(grafo):\n",
    "    # Obtener el coeficiente de clustering para cada vértice\n",
    "    coeficientes = nx.clustering(grafo)\n",
    "    return list(coeficientes.values())\n",
    "\n",
    "# Obtener la lista de coeficientes de clustering\n",
    "coeficientes_clustering = obtenerCoeficienteClustering(grafo)\n",
    "\n",
    "# Añadirlo a la tabla\n",
    "vertices['Clustering'] = coeficientes_clustering\n",
    "vertices.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e3bcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_graphml('data/political-books-network.graphml')\n",
    "nx.draw_random(G, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9bd683",
   "metadata": {},
   "source": [
    "## Selección de datos relacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdccc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#División de atributos y target\n",
    "atributos = vertices[['Label', 'Degree_Centrality', 'High_closeness_centrality',\n",
    "                     'High_betweenness_centrality','Clustering']]\n",
    "objetivo = vertices['political_ideology']\n",
    "\n",
    "#División de los datos en entreamiento y objetivo\n",
    "(atributos_entrenamiento,\n",
    " atributos_prueba,\n",
    " objetivo_entrenamiento,\n",
    " objetivo_prueba) = model_selection.train_test_split(\n",
    "        atributos_codificados,\n",
    "        objetivo_codificado,\n",
    "        # Valor de la semilla aleatoria para que el muestreo sea reproducible a pesar de ser aleatorio\n",
    "        random_state=semilla,\n",
    "        test_size=.33,\n",
    "        stratify=objetivo_codificado\n",
    ")\n",
    "\n",
    "#Creamos nuevos ejemplos para futuras operaciones\n",
    "nuevos_ejemplos = [[1., 0.23, 0.4321, 0.001, 0.333333], [20., 0.115, 0.3095, 0.00521, 0.5], [2., 0.0579, 0.3151, 0.0099, 0.6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f31d14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
