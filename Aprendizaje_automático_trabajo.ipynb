{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ca55ead",
   "metadata": {},
   "source": [
    "# Aprendizaje autom谩tico relacional\n",
    "\n",
    "#### Fernando Jes煤s Fern谩ndez Gallardo\n",
    "#### Carmen Galv谩n L贸pez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a979dd0c",
   "metadata": {},
   "source": [
    "## Preparaci贸n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda48683",
   "metadata": {},
   "source": [
    "#### Imports y variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede9ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn import preprocessing, model_selection, naive_bayes\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "semilla = 86\n",
    "test_size= .33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62d4c7b",
   "metadata": {},
   "source": [
    "#### Lectura y procesamiento inicial de los datos brutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aea927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leemos los archivos\n",
    "aristas = read_csv('data/political-books-edges.csv')\n",
    "vertices = read_csv('data/political-books-nodes.csv')\n",
    "\n",
    "#Borramos la columna ID\n",
    "del(vertices['Id'])\n",
    "\n",
    "#Mostramos las primeras 35 filas\n",
    "vertices.head(35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f366b383",
   "metadata": {},
   "source": [
    "#### Selecci贸n y validaci贸n de los datos brutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Comprobamos que el dataset es v谩lido verificando que no existen duplicados\n",
    "\"\"\"\n",
    "if len(vertices) != len(set(vertices['Label'])):\n",
    "    raise ValueError(\"El dataset no es v谩lido ya que contiene duplicados\")\n",
    "\"\"\"\n",
    "La mejor forma de identificar cada uno de los elementos que forma parte\n",
    "del conjunto de entrenamiento es el nombre del propio libro (que en el dataset\n",
    "se llama 'Label') en vez del ID o cualquier otro tipo de indentificador m谩s\n",
    "complejo. De esta forma, tambi茅n es m谩s f谩cil identificar elementos duplicados\n",
    "(si los hubiera)\n",
    "\"\"\"\n",
    "atributos = vertices['Label']\n",
    "\"\"\"\n",
    "Nuestro objetivo es predecir la ideolog铆a pol铆tica del autor bas谩ndonos en\n",
    "sus obras, por lo que el objetivo que perseguimos en nuestro modelo\n",
    "es el de la ideolog铆a pol铆tica\n",
    "\"\"\"\n",
    "objetivo = vertices['political_ideology']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5904808a",
   "metadata": {},
   "source": [
    "## Inicio del entrenamiento\n",
    "#### Codificaci贸n del objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1361f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Para poder trabajar con los datos que tenemos, necesitamos convertirlos en un formato que sklearn pueda \"entender\".\n",
    "Debemos de hacer que nuestros datos \"planos\" sean para sklearn objetos \"comparables\", dependiendo del tipo de\n",
    "ordenaci贸n que nosotros veamos m谩s apropiada para el m茅todo en cuesti贸n\n",
    "(de una manera similar hacemos en Java cuando implementamos la interfaz 'Comparable' y el m茅todo compareTo)\n",
    "\n",
    "El codificador adecuado para la variable objetivo es LabelEncoder, que trabaja\n",
    "con una lista o array unidimensional de sus valores y admite cadenas\n",
    "\n",
    "\"\"\"\n",
    "# Codificadores\n",
    "codificador_atributos = preprocessing.LabelEncoder()\n",
    "codificador_objetivo = preprocessing.LabelEncoder()\n",
    "# Datos codificados\n",
    "atributos_codificados = codificador_atributos.fit_transform(atributos)\n",
    "objetivo_codificado = codificador_objetivo.fit_transform(objetivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177b9190",
   "metadata": {},
   "source": [
    "#### Divisi贸n en conjunto de entrenamiento y conjunto de prueba\n",
    "\n",
    "Partimos el atributo y el objetivo en dos, de entrenamiento y de prueba. Esto se hace para evitar el sobreajuste, que es cuando el modelo se adapta demasiado a los datos de entrenamiento y pierde capacidad de generalizar a nuevos casos.\n",
    "\n",
    "Reservamos con `test_size` el 33% del total de los datos para la posterior prueba. El resto se usa para el entrenamiento.\n",
    "\n",
    "Con `stratify` indicamos la divisi贸n que debe mantener la proporci贸n de clases en ambos conjuntos, es decir, que si hay un 40% de conservadores, un 30% de neutrales y un 30% de liberales en el conjunto original, tambi茅n haya esa proporci贸n en el conjunto de entrenamiento y en el de prueba. Esto se hace para evitar sesgos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f3f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "(atributos_entrenamiento,\n",
    " atributos_prueba,\n",
    " objetivo_entrenamiento,\n",
    " objetivo_prueba) = model_selection.train_test_split(\n",
    "        atributos_codificados,\n",
    "        objetivo_codificado,\n",
    "        # Valor de la semilla aleatoria para que el muestreo sea reproducible a pesar de ser aleatorio\n",
    "        random_state=semilla,\n",
    "        test_size=test_size,\n",
    "        stratify=objetivo_codificado\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b90d68",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "#### No relacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6bc29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "El m茅todo reshape solo cambia la forma del array, pero no su contenido.\n",
    "El clasificador MultinomialNB de sklearn espera un array 2D porque puede manejar\n",
    "m煤ltiples caracter铆sticas por muestra, pero en nuestro caso solo tenemos una caracter铆stica por muestra,\n",
    "que es el nombre del libro.\n",
    "\"\"\"\n",
    "atr_cod_reshaped = atributos_codificados.reshape(-1, 1)\n",
    "atr_pr_reshaped = atributos_prueba.reshape(-1, 1)\n",
    "atr_ent_reshaped = atributos_entrenamiento.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76cac28",
   "metadata": {},
   "source": [
    "## Explicaci贸n de Bing, borrar antes de entregar:\n",
    "\n",
    "```\n",
    "Lo que haces con ese c贸digo es crear y entrenar un clasificador de Naive Bayes no relacional, que es un tipo de modelo que asume que los atributos son independientes entre s铆 dada la clase. Es decir, que la probabilidad de que un libro tenga un cierto t铆tulo no depende de la probabilidad de que tenga otra caracter铆stica, como el autor o el g茅nero. Esto simplifica el c谩lculo de las probabilidades, pero puede ser una suposici贸n muy fuerte en algunos casos.\n",
    "\n",
    "El clasificador que usas es el MultinomialNB, que es adecuado para atributos discretos que representan frecuencias o conteos. Por ejemplo, si los t铆tulos de los libros se representan como vectores de palabras, donde cada posici贸n indica cu谩ntas veces aparece una palabra en el t铆tulo. El par谩metro alpha es el suavizado, que es una t茅cnica para evitar que las probabilidades sean cero cuando hay palabras que no aparecen en el conjunto de entrenamiento. Un valor t铆pico es 1, pero puedes probar otros valores para ver c贸mo afectan al rendimiento del modelo.\n",
    "\n",
    "El m茅todo fit es el que entrena el modelo con los datos de entrenamiento. Le pasas los atributos y los objetivos codificados, y el modelo aprende las probabilidades de cada clase y de cada atributo dado cada clase. Estas probabilidades se almacenan en los atributos class_log_prior_ y feature_log_prob_ del modelo.\n",
    "\n",
    "El bucle for que haces al final es para mostrar la cantidad de ejemplos y el logaritmo de la probabilidad de cada clase. El logaritmo se usa para evitar problemas de desbordamiento o subdesbordamiento cuando se multiplican muchas probabilidades peque帽as. La clase 0 corresponde a conservador, la 1 a neutral y la 2 a liberal.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a186a730",
   "metadata": {},
   "outputs": [],
   "source": [
    "suavizado = 1\n",
    "\n",
    "clasif_NB = naive_bayes.MultinomialNB(alpha=suavizado)\n",
    "clasif_NB.fit(atr_ent_reshaped, objetivo_entrenamiento)\n",
    "\n",
    "#Calculamos la cantidad de ejemplos para cada clase y los logaritmos\n",
    "for clase, cantidad_ejemplos_clase, log_probabilidad_clase in zip(\n",
    "        clasif_NB.classes_, clasif_NB.class_count_, clasif_NB.class_log_prior_):\n",
    "    print(f\"Cantidad de ejemplos para la clase {0}: {1}\", clase, cantidad_ejemplos_clase)\n",
    "    print(f\"Logaritmo de la probabilidad aprendida para la clase {0}: {1}\", clase, log_probabilidad_clase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eefd783",
   "metadata": {},
   "source": [
    "## EXPLICACIN DE BING, BORRAR\n",
    "\n",
    "```\n",
    "Lo que haces con ese c贸digo es evaluar el rendimiento del modelo de Naive Bayes que has entrenado. Para ello, usas varias t茅cnicas:\n",
    "\n",
    "- Primero, usas el m茅todo predict para obtener las predicciones del modelo para los datos de prueba. Le pasas los atributos de prueba codificados y te devuelve un arreglo con los objetivos predichos. Estos los puedes comparar con los objetivos reales para ver cu谩ntos aciertos y errores tiene el modelo.\n",
    "- Luego, usas el m茅todo score para obtener la precisi贸n del modelo, que es la proporci贸n de aciertos sobre el total de casos. Le pasas los atributos y los objetivos de prueba codificados y te devuelve un valor entre 0 y 1, donde 1 significa que el modelo acierta todos los casos y 0 que falla todos.\n",
    "- Despu茅s, usas la t茅cnica de cross validation, que es una forma de estimar la precisi贸n del modelo usando diferentes particiones de los datos. Creas un objeto ShuffleSplit que define c贸mo se van a dividir los datos en cada iteraci贸n. En este caso, haces 10 iteraciones, reservando el 33% de los datos para la prueba y usando la misma semilla aleatoria que antes. Luego, usas la funci贸n cross_val_score para obtener la precisi贸n del modelo en cada iteraci贸n. Le pasas el modelo, los atributos y los objetivos codificados de todo el conjunto de datos y el objeto ShuffleSplit. Te devuelve un arreglo con las precisiones obtenidas en cada iteraci贸n.\n",
    "- Finalmente, usas la funci贸n np.mean para obtener la media de las precisiones obtenidas con cross validation. Esto te da una idea de c贸mo se comporta el modelo en promedio con diferentes conjuntos de datos.\n",
    "\n",
    "Con todo esto, puedes tener una medida m谩s robusta y confiable del rendimiento del modelo de Naive Bayes. Espero haberte ayudado a entender mejor lo que est谩 sucediendo en tu c贸digo. \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f2c42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ShuffleSplit es necesario para la CrossValidation\n",
    "\"\"\"\n",
    "cv = ShuffleSplit(n_splits=10, test_size=test_size, random_state=semilla)\n",
    "\n",
    "\n",
    "#Probamos la predicci贸n con los atributos de prueba\n",
    "print('Predicci贸n con Naive Bayes: ', clasif_NB.predict(atr_pr_reshaped))\n",
    "#Hacemos el score con naive bayes\n",
    "print('Precisi贸n con Naive Bayes: ', clasif_NB.score(atr_pr_reshaped, objetivo_prueba))\n",
    "#Hacemos el score con cross validation\n",
    "print('Precisi贸n con cross validation: ', cross_val_score(clasif_NB, atr_cod_reshaped, objetivo_codificado, cv=cv))\n",
    "#Hacemos la media de score de cross validation, ya que al final es lo que nos interesa\n",
    "print(f'Media de precisi贸n: {0}', np.mean(cross_val_score(clasif_NB, atr_cod_reshaped, objetivo_codificado, cv=cv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577a612a",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7dfafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a utilizar este modelo ya que nos viene bien al tener un dataset peque帽o. Este modelo aumenta\n",
    "#el tiempo de entrenamiento cuadr谩tricamente con el n煤mero de ejemplos\n",
    "\n",
    "classif_SVC = SVC().fit(atr_ent_reshaped, objetivo_entrenamiento)\n",
    "\n",
    "\n",
    "#Probamos la predicci贸n con los atributos de prueba\n",
    "print('Predicci贸n SVC: ', classif_SVC.predict(atr_pr_reshaped))\n",
    "#Hacemos el score con kNN\n",
    "print('Precisi贸n SVC: ', classif_SVC.score(atr_pr_reshaped, objetivo_prueba))\n",
    "#Hacemos el score con cross validation\n",
    "print(f'Precisi贸n cross validation: {0}', np.mean(cross_val_score(classif_SVC, atr_cod_reshaped, objetivo_codificado, cv=cv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c740039",
   "metadata": {},
   "source": [
    "## Sacar m茅tricas relacionales"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
